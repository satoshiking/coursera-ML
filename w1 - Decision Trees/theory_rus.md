<h3>Задание по программированию: Важность признаков</h3>
Данное задание основано на материалах лекций по логическим методам и направлено на знакомство c решающими деревьями (Decision Trees).

<h4>Вы научитесь:</h4>
- обучать решающие деревья
- находить наиболее важные для них признаки

<h4>Введение</h4>
Решающие деревья относятся к классу логических методов. Их основная идея состоит в объединении определенного количества простых решающих правил, благодаря чему итоговый алгоритм является интерпретируемым. Как следует из названия, решающее дерево представляет собой бинарное дерево, в котором каждой вершине сопоставлено некоторое правило вида "j-й признак имеет значение меньше b". В листьях этого дерева записаны числа-предсказания. Чтобы получить ответ, нужно стартовать из корня и делать переходы либо в левое, либо в правое поддерево в зависимости от того, выполняется правило из текущей вершины или нет.<br><br>

Одна из особенностей решающих деревьев заключается в том, что они позволяют получать важности всех используемых признаков. Важность признака можно оценить на основе того, как сильно улучшился критерий качества благодаря использованию этого признака в вершинах дерева.

<h4>Данные</h4>
В этом задании мы вновь рассмотрим данные о пассажирах Титаника. Будем решать на них задачу классификации, в которой по различным характеристикам пассажиров требуется предсказать, кто из них выжил после крушения корабля.

<h4>Реализация в Scikit-Learn</h4>
В библиотеке scikit-learn решающие деревья реализованы в классах sklearn.tree.DecisionTreeСlassifier (для классификации) и sklearn.tree.DecisionTreeRegressor (для регрессии). Обучение модели производится с помощью функции fit.<br>

Пример использования:<br>
1. import numpy as np
2. from sklearn.tree import DecisionTreeClassifier
3. X = np.array([[1, 2], [3, 4], [5, 6]])
4. y = np.array([0, 1, 0])
5. clf = DecisionTreeClassifier()
6. clf.fit(X, y)

В этом задании вам также потребуется находить важность признаков. Это можно сделать, имея уже обученный классификатор:<br>
importances = clf.feature_importances_

Переменная importances будет содержать массив "важностей" признаков. Индекс в этом массиве соответствует индексу признака в данных.

Стоит обратить внимание, что данные могут содержать пропуски. Pandas хранит такие значения как nan (not a number). Для того, чтобы проверить, является ли число nan'ом, можно воспользоваться функцией np.isnan.

Пример использования:<br>
np.isnan(X)

Материалы
- Подробнее про решающие деревья в sklearn
- Работа с пропущенными значениями в pandas
- Подробнее о деревьях и их построении

